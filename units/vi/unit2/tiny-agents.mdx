# Tiny Agents: M·ªôt agent ch·∫°y b·∫±ng MCP ch·ªâ v·ªõi 50 d√≤ng m√£

Sau khi ƒë√£ x√¢y d·ª±ng c√°c m√°y ch·ªß MCP b·∫±ng Gradio, gi·ªù ch√∫ng ta s·∫Ω kh√°m ph√° s√¢u h∆°n v·ªÅ m√°y kh√°ch MCP. Ph·∫ßn n√†y ph√°t tri·ªÉn t·ª´ d·ª± √°n th·ª≠ nghi·ªám [Tiny Agents](https://huggingface.co/blog/tiny-agents) - minh h·ªça c√°ch tri·ªÉn khai m√°y kh√°ch MCP si√™u ƒë∆°n gi·∫£n c√≥ th·ªÉ k·∫øt n·ªëi v·ªõi c√°c d·ªãch v·ª• nh∆∞ m√°y ch·ªß ph√¢n t√≠ch c·∫£m x√∫c Gradio c·ªßa ch√∫ng ta.

Trong b√†i th·ª±c h√†nh ng·∫Øn n√†y, ch√∫ng m√¨nh s·∫Ω h∆∞·ªõng d·∫´n c√°c b·∫°n c√°ch tri·ªÉn khai m√°y kh√°ch MCP b·∫±ng TypeScript (JS) c√≥ th·ªÉ giao ti·∫øp v·ªõi b·∫•t k·ª≥ m√°y ch·ªß MCP n√†o, bao g·ªìm c·∫£ m√°y ch·ªß ph√¢n t√≠ch c·∫£m x√∫c d·ª±a tr√™n Gradio ƒë√£ x√¢y d·ª±ng ·ªü ph·∫ßn tr∆∞·ªõc. B·∫°n s·∫Ω th·∫•y MCP chu·∫©n h√≥a c√°ch c√°c agent t∆∞∆°ng t√°c v·ªõi c√¥ng c·ª• nh∆∞ th·∫ø n√†o, gi√∫p ph√°t tri·ªÉn AI Agent tr·ªü n√™n ƒë∆°n gi·∫£n h∆°n ƒë√°ng k·ªÉ.

![meme](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/tiny-agents/thumbnail.jpg)
<figcaption>·∫¢nh ƒë∆∞·ª£c cung c·∫•p b·ªüi https://x.com/adamdotdev</figcaption>

Ch√∫ng ta s·∫Ω ch·ªâ c√°ch k·∫øt n·ªëi tiny agent c·ªßa b·∫°n v·ªõi c√°c m√°y ch·ªß MCP ch·∫°y tr√™n Gradio, cho ph√©p n√≥ t·∫≠n d·ª•ng c·∫£ c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c t√πy ch·ªânh c·ªßa b·∫°n l·∫´n c√°c c√¥ng c·ª• c√≥ s·∫µn kh√°c.

## C√°ch ch·∫°y b·∫£n demo ho√†n ch·ªânh

N·∫øu ƒë√£ c√†i NodeJS (v·ªõi `pnpm` ho·∫∑c `npm`), ch·ªâ c·∫ßn ch·∫°y l·ªánh sau trong terminal:

```bash
npx @huggingface/mcp-client
```

ho·∫∑c n·∫øu d√πng `pnpm`:

```bash
pnpx @huggingface/mcp-client
```

L·ªánh n√†y s·∫Ω c√†i ƒë·∫∑t g√≥i v√†o th∆∞ m·ª•c t·∫°m r·ªìi th·ª±c thi l·ªánh c·ªßa n√≥.

B·∫°n s·∫Ω th·∫•y Agent ƒë∆°n gi·∫£n c·ªßa m√¨nh k·∫øt n·ªëi v·ªõi nhi·ªÅu m√°y ch·ªß MCP (ch·∫°y local), t·∫£i c√°c c√¥ng c·ª• c·ªßa ch√∫ng (t∆∞∆°ng t·ª± c√°ch n√≥ t·∫£i c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c Gradio c·ªßa b·∫°n), sau ƒë√≥ nh·∫Øc b·∫°n b·∫Øt ƒë·∫ßu h·ªôi tho·∫°i.

<video controls autoplay loop>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/tiny-agents/use-filesystem.mp4" type="video/mp4">
</video>

M·∫∑c ƒë·ªãnh, v√≠ d·ª• c·ªßa ch√∫ng ta k·∫øt n·ªëi v·ªõi hai m√°y ch·ªß MCP:

- M√°y ch·ªß ["h·ªá th·ªëng file" chu·∫©n](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem) - c√≥ quy·ªÅn truy c·∫≠p v√†o Desktop c·ªßa b·∫°n
- M√°y ch·ªß [Playwright MCP](https://github.com/microsoft/playwright-mcp) - bi·∫øt c√°ch d√πng tr√¨nh duy·ªát Chromium trong m√¥i tr∆∞·ªùng sandbox

B·∫°n c√≥ th·ªÉ d·ªÖ d√†ng th√™m m√°y ch·ªß ph√¢n t√≠ch c·∫£m x√∫c Gradio c·ªßa m√¨nh v√†o danh s√°ch n√†y nh∆∞ ch√∫ng ta s·∫Ω minh h·ªça sau.

> [!NOTE]
> L∆∞u √Ω: Hi·ªán t·∫°i t·∫•t c·∫£ m√°y ch·ªß MCP trong tiny agents ƒë·ªÅu l√† c√°c ti·∫øn tr√¨nh local (d√π c√°c m√°y ch·ªß t·ª´ xa s·∫Ω s·ªõm ƒë∆∞·ª£c h·ªó tr·ª£). ƒêi·ªÅu n√†y kh√¥ng bao g·ªìm m√°y ch·ªß Gradio c·ªßa ch√∫ng ta ch·∫°y tr√™n localhost:7860.

ƒê·∫ßu v√†o cho video ƒë·∫ßu ti√™n l√†:

> write a haiku about the Hugging Face community and write it to a file named "hf.txt" on my Desktop

Gi·ªù th·ª≠ prompt li√™n quan ƒë·∫øn duy·ªát Web:

> do a Web Search for HF inference providers on Brave Search and open the first 3 results

<video controls autoplay loop>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/tiny-agents/brave-search.mp4" type="video/mp4">
</video>

V·ªõi c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c Gradio ƒë√£ k·∫øt n·ªëi, ch√∫ng ta c√≥ th·ªÉ h·ªèi t∆∞∆°ng t·ª±:
> analyze the sentiment of this review: "I absolutely loved the product, it exceeded all my expectations!"

### M√¥ h√¨nh v√† nh√† cung c·∫•p m·∫∑c ƒë·ªãnh

V·ªÅ c·∫∑p m√¥ h√¨nh/nh√† cung c·∫•p, Agent m·∫´u c·ªßa ch√∫ng ta m·∫∑c ƒë·ªãnh d√πng:
- ["Qwen/Qwen2.5-72B-Instruct"](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct)
- ch·∫°y tr√™n [Nebius](https://huggingface.co/docs/inference-providers/providers/nebius)

T·∫•t c·∫£ c√†i ƒë·∫∑t n√†y ƒë·ªÅu c√≥ th·ªÉ t√πy ch·ªânh qua bi·∫øn m√¥i tr∆∞·ªùng! ·ªû ƒë√¢y, ch√∫ng ta c≈©ng s·∫Ω h∆∞·ªõng d·∫´n c√°ch th√™m m√°y ch·ªß Gradio MCP c·ªßa m√¨nh:

```ts
const agent = new Agent({
	provider: process.env.PROVIDER ?? "nebius",
	model: process.env.MODEL_ID ?? "Qwen/Qwen2.5-72B-Instruct",
	apiKey: process.env.HF_TOKEN,
	servers: [
		// C√°c m√°y ch·ªß m·∫∑c ƒë·ªãnh
		{
			command: "npx",
			args: ["@modelcontextprotocol/servers", "filesystem"]
		},
		{
			command: "npx",
			args: ["playwright-mcp"]
		},
		// M√°y ch·ªß ph√¢n t√≠ch c·∫£m x√∫c Gradio c·ªßa ch√∫ng ta
		{
			command: "npx",
			args: [
				"mcp-remote",
				"http://localhost:7860/gradio_api/mcp/sse"
			]
		}
	],
});
```

<Tip>

Ch√∫ng ta k·∫øt n·ªëi t·ªõi m√°y ch·ªß MCP d·ª±a tr√™n Gradio th√¥ng qua g√≥i [`mcp-remote`](https://www.npmjs.com/package/mcp-remote).

</Tip>


## N·ªÅn t·∫£ng cho ƒëi·ªÅu n√†y: h·ªó tr·ª£ g·ªçi c√¥ng c·ª• native trong LLMs

ƒêi·ªÅu gi√∫p k·∫øt n·ªëi c√°c m√°y ch·ªß MCP Gradio v·ªõi Tiny Agent c·ªßa ch√∫ng ta l√† c√°c LLM (c·∫£ closed v√† open) g·∫ßn ƒë√¢y ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ g·ªçi h√†m (function calling), hay c√≤n g·ªçi l√† s·ª≠ d·ª•ng c√¥ng c·ª•. Ch√≠nh kh·∫£ nƒÉng n√†y h·ªó tr·ª£ t√≠ch h·ª£p c·ªßa ch√∫ng ta v·ªõi c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c m√† ch√∫ng ta ƒë√£ x√¢y d·ª±ng b·∫±ng Gradio.

M·ªôt c√¥ng c·ª• ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a b·ªüi t√™n, m√¥ t·∫£ v√† bi·ªÉu di·ªÖn JSONSchema c·ªßa c√°c tham s·ªë - gi·ªëng h·ªát c√°ch ch√∫ng ta ƒë·ªãnh nghƒ©a h√†m ph√¢n t√≠ch c·∫£m x√∫c trong m√°y ch·ªß Gradio. H√£y xem m·ªôt v√≠ d·ª• ƒë∆°n gi·∫£n:

<details>
<summary>B·∫•m ƒë·ªÉ xem b·∫£n d·ªãch ti·∫øng Vi·ªát</summary>
```ts
const weatherTool = {
	type: "function",
	function: {
		name: "get_weather",
		description: "Nh·∫≠n nhi·ªát ƒë·ªô hi·ªán t·∫°i cho m·ªôt ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ.",
		parameters: {
			type: "object",
			properties: {
				location: {
					type: "string",
					description: "Th√†nh ph·ªë v√† qu·ªëc gia, v√≠ d·ª•: H√† N·ªôi, Vi·ªát Nam",
				},
			},
		},
	},
};
```
</details>

```ts
const weatherTool = {
	type: "function",
	function: {
		name: "get_weather",
		description: "Get current temperature for a given location.",
		parameters: {
			type: "object",
			properties: {
				location: {
					type: "string",
					description: "City and country e.g. Bogot√°, Colombia",
				},
			},
		},
	},
};
```

C√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c Gradio c·ªßa ch√∫ng ta s·∫Ω c√≥ c·∫•u tr√∫c t∆∞∆°ng t·ª±, v·ªõi `text` l√†m tham s·ªë ƒë·∫ßu v√†o thay v√¨ `location`.

T√†i li·ªáu ch√≠nh th·ª©c m√† m√¨nh s·∫Ω li√™n k·∫øt ·ªü ƒë√¢y l√† [t√†i li·ªáu function calling c·ªßa OpenAI](https://platform.openai.com/docs/guides/function-calling?api-mode=chat). (ƒê√∫ng v·∫≠y... OpenAI g·∫ßn nh∆∞ ƒë·ªãnh nghƒ©a c√°c ti√™u chu·∫©n LLM cho c·∫£ c·ªông ƒë·ªìng üòÖ).

C√°c inference engine cho ph√©p b·∫°n truy·ªÅn m·ªôt danh s√°ch c√¥ng c·ª• khi g·ªçi LLM, v√† LLM c√≥ th·ªÉ t·ª± do g·ªçi kh√¥ng, m·ªôt ho·∫∑c nhi·ªÅu c√¥ng c·ª• trong s·ªë ƒë√≥.
L√† m·ªôt developer, b·∫°n ch·∫°y c√°c c√¥ng c·ª• v√† ƒë∆∞a k·∫øt qu·∫£ c·ªßa ch√∫ng tr·ªü l·∫°i LLM ƒë·ªÉ ti·∫øp t·ª•c qu√° tr√¨nh sinh k·∫øt qu·∫£.

> L∆∞u √Ω r·∫±ng ·ªü backend (·ªü c·∫•p ƒë·ªô inference engine), c√°c c√¥ng c·ª• ƒë∆°n gi·∫£n ƒë∆∞·ª£c truy·ªÅn v√†o m√¥ h√¨nh trong m·ªôt `chat_template` ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng ƒë·∫∑c bi·ªát, gi·ªëng nh∆∞ b·∫•t k·ª≥ tin nh·∫Øn n√†o kh√°c, sau ƒë√≥ ƒë∆∞·ª£c ph√¢n t√≠ch t·ª´ ph·∫£n h·ªìi (s·ª≠ d·ª•ng c√°c token ƒë·∫∑c bi·ªát c·ªßa m√¥ h√¨nh) ƒë·ªÉ hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng c√°c l·ªánh g·ªçi c√¥ng c·ª•.

## Tri·ªÉn khai MCP client tr√™n InferenceClient

Gi·ªù ch√∫ng ta ƒë√£ bi·∫øt tool l√† g√¨ trong c√°c LLM hi·ªán ƒë·∫°i, h√£y c√πng tri·ªÉn khai MCP client th·ª±c t·∫ø ƒë·ªÉ giao ti·∫øp v·ªõi Gradio server v√† c√°c MCP server kh√°c.

T√†i li·ªáu ch√≠nh th·ª©c t·∫°i https://modelcontextprotocol.io/quickstart/client kh√° chi ti·∫øt. B·∫°n ch·ªâ c·∫ßn thay th·∫ø m·ªçi ƒë·ªÅ c·∫≠p ƒë·∫øn SDK client Anthropic b·∫±ng b·∫•t k·ª≥ SDK client t∆∞∆°ng th√≠ch OpenAI n√†o kh√°c. (C√≥ m·ªôt file [llms.txt](https://modelcontextprotocol.io/llms-full.txt) b·∫°n c√≥ th·ªÉ d√πng ƒë·ªÉ hu·∫•n luy·ªán LLM c·ªßa m√¨nh h·ªó tr·ª£ vi·∫øt code).

Nh·∫Øc l·∫°i, ch√∫ng ta d√πng `InferenceClient` c·ªßa HF cho inference client.

> [!TIP]
> File code ho√†n ch·ªânh `McpClient.ts` c√≥ t·∫°i [ƒë√¢y](https://github.com/huggingface/huggingface.js/blob/main/packages/mcp-client/src/McpClient.ts) n·∫øu b·∫°n mu·ªën xem code th·ª±c t·∫ø ü§ì

L·ªõp `McpClient` c·ªßa ch√∫ng ta c√≥:
- M·ªôt Inference Client (ho·∫°t ƒë·ªông v·ªõi m·ªçi Nh√† cung c·∫•p Inference, v√† `huggingface/inference` h·ªó tr·ª£ c·∫£ endpoint t·ª´ xa l·∫´n local)
- M·ªôt t·∫≠p h·ª£p c√°c phi√™n MCP client, m·ªói phi√™n cho m·ªôt MCP server ƒë∆∞·ª£c k·∫øt n·ªëi (cho ph√©p k·∫øt n·ªëi ƒë·∫øn nhi·ªÅu server, bao g·ªìm c·∫£ Gradio server c·ªßa ch√∫ng ta)
- Danh s√°ch c√°c tool kh·∫£ d·ª•ng s·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn t·ª´ c√°c server ƒë√£ k·∫øt n·ªëi v√† ƒë·ªãnh d·∫°ng l·∫°i m·ªôt ch√∫t.

```ts
export class McpClient {
	protected client: InferenceClient;
	protected provider: string;
	protected model: string;
	private clients: Map<ToolName, Client> = new Map();
	public readonly availableTools: ChatCompletionInputTool[] = [];

	constructor({ provider, model, apiKey }: { provider: InferenceProvider; model: string; apiKey: string }) {
		this.client = new InferenceClient(apiKey);
		this.provider = provider;
		this.model = model;
	}
	
	// [...]
}
```

ƒê·ªÉ k·∫øt n·ªëi ƒë·∫øn MCP server (nh∆∞ Gradio server ph√¢n t√≠ch c·∫£m x√∫c c·ªßa ch√∫ng ta), SDK TypeScript ch√≠nh th·ª©c `@modelcontextprotocol/sdk/client` cung c·∫•p l·ªõp `Client` v·ªõi ph∆∞∆°ng th·ª©c `listTools()`:

```ts
async addMcpServer(server: StdioServerParameters): Promise<void> {
	const transport = new StdioClientTransport({
		...server,
		env: { ...server.env, PATH: process.env.PATH ?? "" },
	});
	const mcp = new Client({ name: "@huggingface/mcp-client", version: packageVersion });
	await mcp.connect(transport);

	const toolsResult = await mcp.listTools();
	debug(
		"Connected to server with tools:",
		toolsResult.tools.map(({ name }) => name)
	);

	for (const tool of toolsResult.tools) {
		this.clients.set(tool.name, mcp);
	}

	this.availableTools.push(
		...toolsResult.tools.map((tool) => {
			return {
				type: "function",
				function: {
					name: tool.name,
					description: tool.description,
					parameters: tool.inputSchema,
				},
			} satisfies ChatCompletionInputTool;
		})
	);
}
```

`StdioServerParameters` l√† m·ªôt interface t·ª´ MCP SDK gi√∫p b·∫°n d·ªÖ d√†ng t·∫°o m·ªôt process local: nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p, hi·ªán t·∫°i t·∫•t c·∫£ MCP server ƒë·ªÅu l√† c√°c process local, bao g·ªìm c·∫£ Gradio server c·ªßa ch√∫ng ta (d√π ch√∫ng ta truy c·∫≠p qua HTTP).

V·ªõi m·ªói MCP server ƒë∆∞·ª£c k·∫øt n·ªëi (bao g·ªìm Gradio server ph√¢n t√≠ch c·∫£m x√∫c), ch√∫ng ta ƒë·ªãnh d·∫°ng l·∫°i danh s√°ch tool c·ªßa n√≥ v√† th√™m v√†o `this.availableTools`.

### C√°ch s·ª≠ d·ª•ng c√°c c√¥ng c·ª•

S·ª≠ d·ª•ng c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c c·ªßa ch√∫ng ta (ho·∫∑c b·∫•t k·ª≥ c√¥ng c·ª• MCP n√†o kh√°c) r·∫•t ƒë∆°n gi·∫£n. B·∫°n ch·ªâ c·∫ßn truy·ªÅn `this.availableTools` v√†o LLM chat-completion, c√πng v·ªõi m·∫£ng messages th√¥ng th∆∞·ªùng:

```ts
const stream = this.client.chatCompletionStream({
	provider: this.provider,
	model: this.model,
	messages,
	tools: this.availableTools,
	tool_choice: "auto",
});
```

`tool_choice: "auto"` l√† tham s·ªë b·∫°n truy·ªÅn ƒë·ªÉ LLM c√≥ th·ªÉ t·∫°o ra kh√¥ng, m·ªôt ho·∫∑c nhi·ªÅu l·ªánh g·ªçi c√¥ng c·ª•.

Khi ph√¢n t√≠ch ho·∫∑c stream k·∫øt qu·∫£, LLM s·∫Ω t·∫°o ra c√°c l·ªánh g·ªçi c√¥ng c·ª• (v√≠ d·ª•: t√™n h√†m v√† c√°c ƒë·ªëi s·ªë ƒë∆∞·ª£c m√£ h√≥a JSON) m√† b·∫°n (v·ªõi t∆∞ c√°ch l√† nh√† ph√°t tri·ªÉn) c·∫ßn x·ª≠ l√Ω. SDK MCP Client m·ªôt l·∫ßn n·ªØa gi√∫p vi·ªác n√†y tr·ªü n√™n d·ªÖ d√†ng; n√≥ c√≥ ph∆∞∆°ng th·ª©c `client.callTool()`:

```ts
const toolName = toolCall.function.name;
const toolArgs = JSON.parse(toolCall.function.arguments);

const toolMessage: ChatCompletionInputMessageTool = {
	role: "tool",
	tool_call_id: toolCall.id,
	content: "",
	name: toolName,
};

/// L·∫•y session ph√π h·ª£p cho c√¥ng c·ª• n√†y
const client = this.clients.get(toolName);
if (client) {
	const result = await client.callTool({ name: toolName, arguments: toolArgs });
	toolMessage.content = result.content[0].text;
} else {
	toolMessage.content = `Error: No session found for tool: ${toolName}`;
}
```

N·∫øu LLM ch·ªçn s·ª≠ d·ª•ng c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c c·ªßa ch√∫ng ta, ƒëo·∫°n code n√†y s·∫Ω t·ª± ƒë·ªông ƒë·ªãnh tuy·∫øn l·ªánh g·ªçi ƒë·∫øn Gradio server c·ªßa ch√∫ng ta, th·ª±c thi ph√¢n t√≠ch v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ cho LLM.

Cu·ªëi c√πng, b·∫°n s·∫Ω th√™m message c√¥ng c·ª• k·∫øt qu·∫£ v√†o m·∫£ng `messages` v√† ƒë∆∞a ng∆∞·ª£c l·∫°i v√†o LLM.

## Agent 50-d√≤ng-code c·ªßa ch√∫ng ta ü§Ø

Gi·ªù ƒë√¢y khi ƒë√£ c√≥ MCP client c√≥ kh·∫£ nƒÉng k·∫øt n·ªëi ƒë·∫øn c√°c MCP server t√πy √Ω (bao g·ªìm c·∫£ Gradio sentiment analysis server) ƒë·ªÉ l·∫•y danh s√°ch c√¥ng c·ª• v√† ch√®n ch√∫ng v√†o LLM inference, v·∫≠y... Agent l√† g√¨?

> Khi b·∫°n ƒë√£ c√≥ m·ªôt inference client v·ªõi m·ªôt b·ªô c√¥ng c·ª•, th√¨ Agent ch·ªâ ƒë∆°n gi·∫£n l√† m·ªôt v√≤ng l·∫∑p while bao quanh n√≥.

C·ª• th·ªÉ h∆°n, Agent l√† s·ª± k·∫øt h·ª£p c·ªßa:
- m·ªôt system prompt
- m·ªôt LLM Inference client
- m·ªôt MCP client ƒë·ªÉ k·∫øt n·ªëi c√°c c√¥ng c·ª• t·ª´ nhi·ªÅu MCP server (bao g·ªìm Gradio server c·ªßa ch√∫ng ta)
- m·ªôt s·ªë lu·ªìng ƒëi·ªÅu khi·ªÉn c∆° b·∫£n (xem v√≤ng l·∫∑p while b√™n d∆∞·ªõi)

> [!TIP]
> File code ho√†n ch·ªânh `Agent.ts` c√≥ t·∫°i [ƒë√¢y](https://github.com/huggingface/huggingface.js/blob/main/packages/mcp-client/src/Agent.ts).

L·ªõp Agent c·ªßa ch√∫ng ta ƒë∆°n gi·∫£n k·∫ø th·ª´a t·ª´ McpClient:

```ts
export class Agent extends McpClient {
	private readonly servers: StdioServerParameters[];
	protected messages: ChatCompletionInputMessage[];

	constructor({
		provider,
		model,
		apiKey,
		servers,
		prompt,
	}: {
		provider: InferenceProvider;
		model: string;
		apiKey: string;
		servers: StdioServerParameters[];
		prompt?: string;
	}) {
		super({ provider, model, apiKey });
		this.servers = servers;
		this.messages = [
			{
				role: "system",
				content: prompt ?? DEFAULT_SYSTEM_PROMPT,
			},
		];
	}
}
```

M·∫∑c ƒë·ªãnh, ch√∫ng ta s·ª≠ d·ª•ng system prompt ƒë∆°n gi·∫£n l·∫•y c·∫£m h·ª©ng t·ª´ [h∆∞·ªõng d·∫´n prompt GPT-4.1](https://cookbook.openai.com/examples/gpt4-1_prompting_guide).

M·∫∑c d√π ƒëi·ªÅu n√†y ƒë·∫øn t·ª´ OpenAI üòà, nh∆∞ng c√¢u n√†y ƒë·∫∑c bi·ªát √°p d·ª•ng cho ng√†y c√†ng nhi·ªÅu m√¥ h√¨nh, c·∫£ ƒë√≥ng v√† m·ªü:

> Ch√∫ng t√¥i khuy·∫øn kh√≠ch nh√† ph√°t tri·ªÉn ch·ªâ s·ª≠ d·ª•ng tr∆∞·ªùng tools ƒë·ªÉ truy·ªÅn c√¥ng c·ª•, thay v√¨ th·ªß c√¥ng ch√®n m√¥ t·∫£ c√¥ng c·ª• v√†o prompt v√† vi·∫øt parser ri√™ng cho l·ªánh g·ªçi c√¥ng c·ª• nh∆∞ m·ªôt s·ªë ƒë√£ l√†m tr∆∞·ªõc ƒë√¢y.

Nghƒ©a l√† ch√∫ng ta kh√¥ng c·∫ßn cung c·∫•p danh s√°ch v√≠ d·ª• v·ªÅ c√°ch s·ª≠ d·ª•ng c√¥ng c·ª• ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng k·ªπ l∆∞·ª°ng trong prompt. Tham s·ªë `tools: this.availableTools` l√† ƒë·ªß, v√† LLM s·∫Ω bi·∫øt c√°ch s·ª≠ d·ª•ng c·∫£ c√¥ng c·ª• h·ªá th·ªëng file v√† c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c Gradio c·ªßa ch√∫ng ta.

Vi·ªác t·∫£i c√¥ng c·ª• l√™n Agent ƒë∆°n gi·∫£n ch·ªâ l√† k·∫øt n·ªëi ƒë·∫øn c√°c MCP server mong mu·ªën (song song v√¨ r·∫•t d·ªÖ th·ª±c hi·ªán trong JS):

```ts
async loadTools(): Promise<void> {
	await Promise.all(this.servers.map((s) => this.addMcpServer(s)));
}
```

Ch√∫ng ta th√™m hai c√¥ng c·ª• b·ªï sung (ngo√†i MCP) m√† LLM c√≥ th·ªÉ s·ª≠ d·ª•ng cho lu·ªìng ƒëi·ªÅu khi·ªÉn c·ªßa Agent:

```ts
const taskCompletionTool: ChatCompletionInputTool = {
	type: "function",
	function: {
		name: "task_complete",
		description: "Call this tool when the task given by the user is complete",
		parameters: {
			type: "object",
			properties: {},
		},
	},
};
const askQuestionTool: ChatCompletionInputTool = {
	type: "function",
	function: {
		name: "ask_question",
		description: "Ask a question to the user to get more info required to solve or clarify their problem.",
		parameters: {
			type: "object",
			properties: {},
		},
	},
};
const exitLoopTools = [taskCompletionTool, askQuestionTool];
```

Khi g·ªçi b·∫•t k·ª≥ c√¥ng c·ª• n√†o trong s·ªë n√†y, Agent s·∫Ω ng·∫Øt v√≤ng l·∫∑p v√† tr·∫£ l·∫°i quy·ªÅn ki·ªÉm so√°t cho ng∆∞·ªùi d√πng ƒë·ªÉ c√≥ d·ªØ li·ªáu ƒë·∫ßu v√†o m·ªõi.

### V√≤ng l·∫∑p while ho√†n ch·ªânh

H√£y xem v√≤ng l·∫∑p while ho√†n ch·ªânh c·ªßa ch√∫ng t√¥i.üéâ

ƒêi·ªÉm m·∫•u ch·ªët c·ªßa v√≤ng l·∫∑p while ch√≠nh c·ªßa Agent l√† ch√∫ng t√¥i ch·ªâ l·∫∑p l·∫°i v·ªõi LLM lu√¢n phi√™n gi·ªØa vi·ªác g·ªçi c√¥ng c·ª• v√† cung c·∫•p cho n√≥ k·∫øt qu·∫£ c√¥ng c·ª•, v√† ch√∫ng t√¥i l√†m nh∆∞ v·∫≠y **cho ƒë·∫øn khi LLM b·∫Øt ƒë·∫ßu ph·∫£n h·ªìi b·∫±ng hai th√¥ng b√°o kh√¥ng ph·∫£i c√¥ng c·ª• li√™n ti·∫øp**.

ƒê√¢y l√† v√≤ng l·∫∑p while ho√†n ch·ªânh:

```ts
let numOfTurns = 0;
let nextTurnShouldCallTools = true;
while (true) {
	try {
		yield* this.processSingleTurnWithTools(this.messages, {
			exitLoopTools,
			exitIfFirstChunkNoTool: numOfTurns > 0 && nextTurnShouldCallTools,
			abortSignal: opts.abortSignal,
		});
	} catch (err) {
		if (err instanceof Error && err.message === "AbortError") {
			return;
		}
		throw err;
	}
	numOfTurns++;
	const currentLast = this.messages.at(-1)!;
	if (
		currentLast.role === "tool" &&
		currentLast.name &&
		exitLoopTools.map((t) => t.function.name).includes(currentLast.name)
	) {
		return;
	}
	if (currentLast.role !== "tool" && numOfTurns > MAX_NUM_TURNS) {
		return;
	}
	if (currentLast.role !== "tool" && nextTurnShouldCallTools) {
		return;
	}
	if (currentLast.role === "tool") {
		nextTurnShouldCallTools = false;
	} else {
		nextTurnShouldCallTools = true;
	}
}
```

## K·∫øt n·ªëi Tiny Agents v·ªõi Gradio MCP Servers

Gi·ªù th√¨ ch√∫ng ta ƒë√£ hi·ªÉu v·ªÅ c·∫£ Tiny Agents v√† Gradio MCP servers, h√£y xem c√°ch ch√∫ng ho·∫°t ƒë·ªông c√πng nhau nh√©! ƒêi·ªÉm tuy·ªát v·ªùi c·ªßa MCP l√† n√≥ cung c·∫•p c√°ch chu·∫©n h√≥a ƒë·ªÉ c√°c agent t∆∞∆°ng t√°c v·ªõi b·∫•t k·ª≥ server n√†o t∆∞∆°ng th√≠ch MCP, bao g·ªìm c·∫£ m√°y ch·ªß ph√¢n t√≠ch c·∫£m x√∫c (sentiment analysis) d·ª±a tr√™n Gradio c·ªßa ch√∫ng ta.

### S·ª≠ d·ª•ng Gradio Server v·ªõi Tiny Agents

ƒê·ªÉ k·∫øt n·ªëi Tiny Agent c·ªßa ch√∫ng ta v·ªõi m√°y ch·ªß ph√¢n t√≠ch c·∫£m x√∫c Gradio ƒë√£ x√¢y d·ª±ng tr∆∞·ªõc ƒë√≥, ch√∫ng ta ch·ªâ c·∫ßn th√™m n√≥ v√†o danh s√°ch servers. D∆∞·ªõi ƒë√¢y l√† c√°ch ch√∫ng ta c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh c·∫•u h√¨nh agent:

```ts
const agent = new Agent({
    provider: process.env.PROVIDER ?? "nebius",
    model: process.env.MODEL_ID ?? "Qwen/Qwen2.5-72B-Instruct",
    apiKey: process.env.HF_TOKEN,
    servers: [
        // ... existing servers ...
        {
            command: "npx",
            args: [
                "mcp-remote",
                "http://localhost:7860/gradio_api/mcp/sse"  // Your Gradio MCP server
            ]
        }
    ],
});
```

Gi·ªù ƒë√¢y agent c·ªßa ch√∫ng ta ƒë√£ c√≥ th·ªÉ s·ª≠ d·ª•ng c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c c√πng v·ªõi c√°c c√¥ng c·ª• kh√°c! V√≠ d·ª•, n√≥ c√≥ th·ªÉ:
1. ƒê·ªçc vƒÉn b·∫£n t·ª´ file b·∫±ng filesystem server
2. Ph√¢n t√≠ch c·∫£m x√∫c b·∫±ng Gradio server c·ªßa ch√∫ng ta
3. Ghi k·∫øt qu·∫£ tr·ªü l·∫°i file

### V√≠ d·ª• t∆∞∆°ng t√°c

ƒê√¢y l√† v√≠ d·ª• v·ªÅ cu·ªôc h·ªôi tho·∫°i v·ªõi agent:

```
User: Read the file "feedback.txt" from my Desktop and analyze its sentiment

Agent: I'll help you analyze the sentiment of the feedback file. Let me break this down into steps:

1. First, I'll read the file using the filesystem tool
2. Then, I'll analyze its sentiment using the sentiment analysis tool
3. Finally, I'll write the results to a new file

[Agent ti·∫øn h√†nh s·ª≠ d·ª•ng c√°c c√¥ng c·ª• v√† cung c·∫•p ph√¢n t√≠ch]
```

### L∆∞u √Ω khi tri·ªÉn khai

Khi tri·ªÉn khai Gradio MCP server c·ªßa b·∫°n l√™n Hugging Face Spaces, b·∫°n c·∫ßn c·∫≠p nh·∫≠t URL server trong c·∫•u h√¨nh agent ƒë·ªÉ tr·ªè t·ªõi space ƒë√£ tri·ªÉn khai:

```ts
{
    command: "npx",
    args: [
        "mcp-remote",
        "https://YOUR_USERNAME-mcp-sentiment.hf.space/gradio_api/mcp/sse"
    ]
}
```

C√°ch n√†y cho ph√©p agent c·ªßa b·∫°n s·ª≠ d·ª•ng c√¥ng c·ª• ph√¢n t√≠ch c·∫£m x√∫c t·ª´ b·∫•t k·ª≥ ƒë√¢u, kh√¥ng ch·ªâ tr√™n local!